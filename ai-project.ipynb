{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.80611111 0.83055556 0.82188889 0.84155556 0.85677778]\n",
      "Mean cross-validation score: 0.8313777777777778\n",
      "Metrics calculated: {'Accuracy': 0.8805777777777778, 'Precision': 0.8756209610382447, 'Recall': 0.8805777777777778, 'F1 Score': 0.8748263791880365, 'AUC-ROC': 0.93567315, 'Matthews Correlation Coefficient': 0.6321123516376986, 'Balanced Accuracy': 0.7868357142857143, 'Jaccard Index': 0.7889753726800517, \"Cohen's Kappa\": 0.6241373950885918}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import uuid\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from evidently.report import Report\n",
    "from evidently.metric_preset import DataDriftPreset\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    matthews_corrcoef,\n",
    "    balanced_accuracy_score,\n",
    "    jaccard_score,\n",
    "    cohen_kappa_score,\n",
    ")\n",
    "\n",
    "class AIModelProcessor:\n",
    "    def __init__(self, model, training_data, target_column, model_version=\"1.0\", model_type=\"Model\", log_file=\"model_logs.json\"):\n",
    "        self.model = model\n",
    "        self.model_type = model_type\n",
    "        self.model_version = model_version\n",
    "        self.log_file = log_file\n",
    "        self.training_data = training_data\n",
    "        self.target_column = target_column\n",
    "\n",
    "        self.x_train = None\n",
    "        self.y_train = None\n",
    "        self.column_names = list(training_data.columns.drop(target_column))\n",
    "        \n",
    "        self._initialize_data()\n",
    "        self._process_data()\n",
    "        self._log_instance(\"Initialized model processor\")\n",
    "\n",
    "    def _initialize_data(self):\n",
    "        self.y_train = self.training_data[self.target_column]\n",
    "        self.x_train = self.training_data.drop(columns=[self.target_column])\n",
    "\n",
    "    def _process_data(self):\n",
    "        # Perform cross-validation\n",
    "        cross_val_scores = self.cross_validation_metrics()\n",
    "\n",
    "        # Calculate metrics\n",
    "        y_pred = self.model.predict(self.x_train)\n",
    "        y_prob = self.model.predict_proba(self.x_train)\n",
    "        metrics = self.calculate_metrics(self.y_train, y_pred, y_prob)\n",
    "\n",
    "        # Generate drift report\n",
    "        drift_report = json.loads(self.evidentlyAi(self.x_train))\n",
    "\n",
    "        # Save logs\n",
    "        log_data = {\n",
    "            \"Model Metrics\": metrics,\n",
    "            \"Cross Validation Scores\": cross_val_scores.tolist(),\n",
    "            \"Data Drift Report\": drift_report,\n",
    "        }\n",
    "        self.save_log(log_data)\n",
    "\n",
    "    def evidentlyAi(self, test_data):\n",
    "\n",
    "        reference_data = self.training_data.drop(columns=[self.target_column])\n",
    "\n",
    "        # If test_data is a feature set, make sure to add the target column for the drift report\n",
    "        if isinstance(test_data, np.ndarray):\n",
    "            test_data = pd.DataFrame(test_data, columns=self.column_names)\n",
    "\n",
    "        # Run Evidently drift detection using the full reference data and features of the test data\n",
    "        report = Report(metrics=[DataDriftPreset()])\n",
    "        report.run(current_data=test_data, reference_data=reference_data)\n",
    "        return report.json()\n",
    "\n",
    "    def calculate_metrics(self, y_true, y_pred, y_prob):\n",
    "        metrics = {\n",
    "            \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "            \"Precision\": precision_score(y_true, y_pred, average=\"weighted\"),\n",
    "            \"Recall\": recall_score(y_true, y_pred, average=\"weighted\"),\n",
    "            \"F1 Score\": f1_score(y_true, y_pred, average=\"weighted\"),\n",
    "            \"AUC-ROC\": roc_auc_score(y_true, y_prob[:, 1], multi_class=\"ovr\"),\n",
    "            \"Matthews Correlation Coefficient\": matthews_corrcoef(y_true, y_pred),\n",
    "            \"Balanced Accuracy\": balanced_accuracy_score(y_true, y_pred),\n",
    "            \"Jaccard Index\": jaccard_score(y_true, y_pred, average=\"weighted\"),\n",
    "            \"Cohen's Kappa\": cohen_kappa_score(y_true, y_pred),\n",
    "        }\n",
    "        print(\"Metrics calculated:\", metrics)\n",
    "        self._log_instance(\"Metrics calculated\", additional_data=metrics)\n",
    "        return metrics\n",
    "\n",
    "    def cross_validation_metrics(self):\n",
    "        cross_val_scores = cross_val_score(self.model, self.x_train, self.y_train, cv=5, scoring=\"accuracy\")\n",
    "        print(f\"Cross-validation scores: {cross_val_scores}\")\n",
    "        print(f\"Mean cross-validation score: {np.mean(cross_val_scores)}\")\n",
    "        self._log_instance(\"Cross-validation performed\", additional_data={\"Cross Validation Scores\": cross_val_scores.tolist()})\n",
    "        return cross_val_scores\n",
    "\n",
    "    def save_log(self, log_data):\n",
    "        timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        log_entry = {\n",
    "            \"Timestamp\": timestamp,\n",
    "            \"Log Data\": log_data\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            with open(self.log_file, 'a') as f:  # Append to log file\n",
    "                json.dump(log_entry, f, indent=4)\n",
    "                f.write(\"\\n\")  # Ensure each log entry is on a new line\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving log to file: {e}\")\n",
    "\n",
    "    def process_input(self, input_data):\n",
    "        input_df = pd.DataFrame([input_data], columns=self.column_names)\n",
    "        prediction = self.model.predict(input_df)\n",
    "        prediction_proba = self.model.predict_proba(input_df)\n",
    "\n",
    "        log_data = {\n",
    "            \"Input Data\": input_data,\n",
    "            \"Prediction\": prediction.tolist(),\n",
    "            \"Prediction Probability\": prediction_proba.tolist(),\n",
    "        }\n",
    "\n",
    "        self._log_instance(\"Processed input data\", additional_data=log_data)\n",
    "        return prediction, prediction_proba\n",
    "\n",
    "    def _log_instance(self, message, additional_data=None):\n",
    "        timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        log_entry = {\n",
    "            \"Timestamp\": timestamp,\n",
    "            \"Event\": message,\n",
    "        }\n",
    "        if additional_data:\n",
    "            log_entry[\"Details\"] = additional_data\n",
    "\n",
    "        try:\n",
    "            with open(self.log_file, 'a') as f:\n",
    "                json.dump(log_entry, f, indent=4)\n",
    "                f.write(\"\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error logging instance event: {e}\")\n",
    "\n",
    "# Example Usage\n",
    "file_path = 'loan_data.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "target_column = 'loan_status'\n",
    "X = df.drop([target_column], axis=1)\n",
    "y = df[target_column]\n",
    "\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == 'object':\n",
    "        X[col] = X[col].astype('category').cat.codes\n",
    "\n",
    "data = pd.concat([X, y], axis=1)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "model.fit(X, y)\n",
    "\n",
    "processor = AIModelProcessor(model, training_data=data, target_column=target_column)\n",
    "\n",
    "# Process a single input\n",
    "test_input = X.iloc[0].to_dict()\n",
    "prediction, prediction_proba = processor.process_input(test_input)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
