{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import uuid\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "from evidently.report import Report\n",
    "from evidently.metric_preset import DataDriftPreset\n",
    "# Removed: from aix360.algorithms.protodash import ProtodashExplainer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, matthews_corrcoef, balanced_accuracy_score, jaccard_score, cohen_kappa_score\n",
    "\n",
    "class AIModelProcessor:\n",
    "    def __init__(self, model, model_version=\"1.0\", model_type=\"Model\", training_data=None, column_names=None):\n",
    "        \"\"\"\n",
    "        Generalized AIModelProcessor class for any model and dataset.\n",
    "\n",
    "        Args:\n",
    "        - model: Any scikit-learn compatible model (e.g., KNeighborsClassifier, RandomForestClassifier, etc.)\n",
    "        - model_version: Version of the model\n",
    "        - model_type: Type or name of the model\n",
    "        - training_data: Dataset used for training, should be a tuple (X_train, y_train)\n",
    "        - column_names: List of column names for the features\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.model_type = model_type\n",
    "        self.model_version = model_version\n",
    "        self.training_data = training_data\n",
    "        self.column_names = column_names\n",
    "        self.x_train = None\n",
    "        self.y_train = None\n",
    "        self.training_data = None\n",
    "        if training_data:\n",
    "            self.update_training_data(*training_data, column_names=column_names)\n",
    "\n",
    "    def update_training_data(self, x_train, y_train, column_names=None):\n",
    "        \"\"\"\n",
    "        Updates the training dataset and prepares the necessary variables.\n",
    "        \"\"\"\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.training_data = pd.DataFrame(x_train, columns=column_names)\n",
    "        self.training_data[\"target\"] = y_train\n",
    "        self.column_names = column_names\n",
    "        print(\"Training data updated successfully.\")\n",
    "\n",
    "    def process_agent_data(self, input_data, decision_outcome, user_feedback=None):\n",
    "        \"\"\"\n",
    "        Processes agent data for a given decision, including feature importance and drift analysis.\n",
    "        \"\"\"\n",
    "        event_id = f\"EVT-{uuid.uuid4().hex[:8]}\"\n",
    "        # Removed the reference to explain_model_features as it was using ProtodashExplainer\n",
    "        agent_data = {\n",
    "            \"Model\": self.model,\n",
    "            \"Timestamp\": time.time(),\n",
    "            \"Event ID\": event_id,\n",
    "            \"AI Model Version\": self.model_version,\n",
    "            \"Model Type\": self.model_type,\n",
    "            \"Input Data\": input_data,\n",
    "            \"Decision Outcome\": decision_outcome,\n",
    "            \"User Feedback\": user_feedback,\n",
    "        }\n",
    "        return self.analyze_agent_data(agent_data)\n",
    "\n",
    "    def analyze_agent_data(self, agent_data, actual_model, reference_data):\n",
    "        \"\"\"\n",
    "        Analyzes the agent data, including performance metrics and potential model drift.\n",
    "        \"\"\"\n",
    "        # Perform actual model evaluation\n",
    "        model_performance_metrics = {\n",
    "            \"accuracy\": actual_model.score(agent_data[\"Input Data\"], agent_data[\"Decision Outcome\"]),\n",
    "            \"precision\": precision_score(agent_data[\"Decision Outcome\"], predicted_labels),\n",
    "            \"recall\": recall_score(agent_data[\"Decision Outcome\"], predicted_labels)\n",
    "        }\n",
    "        \n",
    "        # Perform drift detection\n",
    "        test_data = pd.DataFrame(agent_data[\"Input Data\"], columns=self.column_names)\n",
    "        test_data[\"target\"] = agent_data[\"Decision Outcome\"]\n",
    "        drift_report = self.evidentlyAi(test_data)\n",
    "        \n",
    "        # Prepare final processed data\n",
    "        processed_data = {\n",
    "            \"Alert Severity\": \"High\" if model_performance_metrics[\"accuracy\"] < 90 else \"Low\",\n",
    "            \"Model Performance Metrics\": model_performance_metrics,\n",
    "            \"Decision Rationale\": \"Placeholder or explanation based on model interpretation methods.\",\n",
    "            \"AI Model Drift\": drift_report,\n",
    "            \"Data Drift Report\": drift_report\n",
    "        }\n",
    "    \n",
    "        return processed_data\n",
    "    \n",
    "    def evidentlyAi(self, test_data):\n",
    "        \"\"\"\n",
    "        Performs data drift analysis using the Evidently library.\n",
    "        \"\"\"\n",
    "        # Ensure columns are aligned\n",
    "        if isinstance(test_data, np.ndarray):\n",
    "            test_data = pd.DataFrame(test_data, columns=self.column_names)\n",
    "    \n",
    "        # Drop 'target' column if it exists in the test data (it's only in y_test)\n",
    "        if 'target' in test_data.columns:\n",
    "            test_data = test_data.drop(columns=['target'])\n",
    "        \n",
    "        # Drop 'target' column from the training data for drift analysis (to avoid mismatched columns)\n",
    "        if 'target' in self.training_data.columns:\n",
    "            self.training_data = self.training_data.drop(columns=['target'])\n",
    "    \n",
    "        # Create the Evidently Report object\n",
    "        report = Report(metrics=[DataDriftPreset()])\n",
    "        \n",
    "        # Run the drift report using current data and reference training data\n",
    "        report.run(current_data=test_data, reference_data=self.training_data)\n",
    "        \n",
    "        # Return the drift report in JSON format\n",
    "        return report.json()\n",
    "\n",
    "    def calculate_metrics(self, y_true, y_pred, y_prob):\n",
    "        \"\"\"\n",
    "        Calculates a variety of evaluation metrics.\n",
    "        \"\"\"\n",
    "        metrics = {\n",
    "            \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "            \"Precision\": precision_score(y_true, y_pred, average=\"weighted\"),\n",
    "            \"Recall\": recall_score(y_true, y_pred, average=\"weighted\"),\n",
    "            \"F1 Score\": f1_score(y_true, y_pred, average=\"weighted\"),\n",
    "            \"AUC-ROC\": roc_auc_score(y_true, y_prob[:, 1], multi_class=\"ovr\"),\n",
    "            \"Matthews Correlation Coefficient\": matthews_corrcoef(y_true, y_pred),\n",
    "            \"Balanced Accuracy\": balanced_accuracy_score(y_true, y_pred),\n",
    "            \"Jaccard Index\": jaccard_score(y_true, y_pred, average=\"weighted\"),\n",
    "            \"Cohen's Kappa\": cohen_kappa_score(y_true, y_pred)\n",
    "        }\n",
    "        print(\"Metrics calculated:\", metrics)\n",
    "        return metrics\n",
    "\n",
    "    def cross_validation_metrics(self, X, y):\n",
    "        \"\"\"\n",
    "        Performs cross-validation and returns accuracy scores.\n",
    "        \"\"\"\n",
    "        cross_val_scores = cross_val_score(self.model, X, y, cv=5, scoring=\"accuracy\")\n",
    "        print(f\"Cross-validation scores: {cross_val_scores}\")\n",
    "        print(f\"Mean cross-validation score: {np.mean(cross_val_scores)}\")\n",
    "        return cross_val_scores\n",
    "\n",
    "    def save_log(self, log_data, log_file=\"model_logs.json\", logstash_url=None):\n",
    "        \"\"\"\n",
    "        Saves logs to a file in JSON format and sends logs to Logstash if a URL is provided.\n",
    "        \"\"\"\n",
    "        timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        log_entry = {\n",
    "            \"Timestamp\": timestamp,\n",
    "            \"Log Data\": log_data\n",
    "        }\n",
    "\n",
    "        # Save logs locally in JSON format\n",
    "        try:\n",
    "            with open(log_file, 'a') as f:\n",
    "                json.dump(log_entry, f, indent=4)\n",
    "                f.write(\",\\n\")  # Separate log entries with a newline\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving log to file: {e}\")\n",
    "\n",
    "        # If a Logstash URL is provided, send logs to Logstash\n",
    "        if logstash_url:\n",
    "            try:\n",
    "                response = requests.post(logstash_url, json=log_entry)\n",
    "                if response.status_code == 200:\n",
    "                    print(\"Log successfully sent to Logstash.\")\n",
    "                else:\n",
    "                    print(f\"Failed to send log to Logstash: {response.status_code}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error sending log to Logstash: {e}\")\n",
    "\n",
    "# Example Usage\n",
    "def train_and_process_model(model, X_train, y_train, X_test, y_test, column_names, logstash_url=None):\n",
    "    # Initialize processor\n",
    "    processor = AIModelProcessor(model=model)\n",
    "    processor.update_training_data(X_train, y_train, column_names=column_names)  # Fixed line\n",
    "\n",
    "    # Calculate metrics\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)\n",
    "    metrics = processor.calculate_metrics(y_test, y_pred, y_prob)\n",
    "\n",
    "    # Perform cross-validation\n",
    "    cross_val_scores = processor.cross_validation_metrics(X_train, y_train)\n",
    "\n",
    "    # Save logs in JSON format\n",
    "    log_data = {\n",
    "        \"Model Metrics\": metrics,\n",
    "        \"Cross Validation Scores\": cross_val_scores.tolist(),\n",
    "        \"Data Drift Report\": processor.evidentlyAi(X_test),\n",
    "    }\n",
    "    processor.save_log(log_data, logstash_url=logstash_url)\n",
    "\n",
    "# Example dataset loading\n",
    "file_path = 'loan_data.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "X = df.drop(['loan_status'], axis=1)\n",
    "y = df[\"loan_status\"]\n",
    "\n",
    "# Preprocessing\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == 'object':\n",
    "        X[col] = X[col].astype('category').cat.codes\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Example model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Logstash URL\n",
    "logstash_url = \"http://localhost:5044\"\n",
    "\n",
    "# Process and save data\n",
    "train_and_process_model(model, X_train, y_train, X_test, y_test, list(X.columns), logstash_url)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
